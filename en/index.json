[{"content":"Channel 是 Go 语言的核心数据结构，也是支撑 Go 高性能并发编程的重要结构。在本篇文章中，我们将从 channel 的设计原理、数据结构、发送数据、接收数据以及关闭 channel 这几个方面进行一些深入的分析，帮助大家更好地理解 channel 的工作原理。\n本文源码基于 Go 1.20\nCSP 模型 Go 的并发哲学 Do not communicate by sharing memory; instead, share memory by communicating.\n不要通过共享内存进行通信，而应该通过通信来共享内存。\n这是 Go 的并发哲学，它依赖于 CSP 模型，基于 channel 实现。\nCSP 的全称是 “Communicating Sequential Processes”，这也是 1978 年 ACM 期刊中 Charles Antony Richard Hoare 写的经典同名论文。在文章中，CSP 也是一门自定义的编程语言，该语言描述了并发过程之间的交互作用。\n相对于使用 sync.Mutex 这样的并发原语，虽然大多数锁的问题可以通过 channel 或者传统的锁两种方式之一解决，但是 Go 语言核心团队更加推荐使用 CSP 的方式。\n数据结构 channel 的数据结构源码位于src/runtime/chan.go 中，如下所示：\n// src/runtime/chan.go type hchan struct { qcount uint // 环形缓冲区中的元素个数 dataqsiz uint // 环形缓冲区的 size buf unsafe.Pointer // 指向环形缓冲区的指针（只针对有缓冲的 channel） elemsize uint16 // chan 中元素大小 closed uint32 elemtype *_type // 元素类型 sendx uint // 已发送元素在环形缓冲区中的索引 recvx uint // 已接收元素在环形缓冲区中的索引 recvq waitq // 接收等待队列 sendq waitq // 发送等待队列 lock mutex // runtime 包提供的互斥锁 } 其中，lock 是一个互斥锁，它会保护 hchan 中的所有字段，也是 channel 线程安全的保证。\n等待队列使用双向链表 waitq 表示，链表中的所有元素都是 sudog 结构：\n// src/runtime/chan.go type waitq struct { first *sudog last *sudog } sudog 表示一个在等待队列中的 g . 其中存储了两个分别指向前后的 sudog 指针以构成链表。 g 与同步对象的关系是多对多的，所以一个 g 可以出现在多个等待队列上面，因此一个 g 可能有多个 sudog ，并且多个 g 可能在等待同一个同步对象，因此一个对象可能有许多 sudog . sudog 是从特殊池中分配出来的。 使用acquireSudog() 和 releaseSudog(s *sudog) 分配和释放它们。sudog 中所有字段都受到 hchan.lock 保护。\n// src/runtime/runtime2.go type sudog struct { g *g next *sudog prev *sudog elem unsafe.Pointer // 指向数据（可能指向栈） // 这三个字段永远不会被同时访问 // 对 channel 来说，waitlink 只由 g 使用。 // 对 semaphores 来说，只有在持有 semaRoot 锁的时候才能访问这三个字段。 acquiretime int64 releasetime int64 ticket uint32 // isSelect 表示 g 是否正在参与选择 // g.selectDone 必须进行 CAS 才能在被唤醒的竞争中胜出。 isSelect bool // success 表示 channel c 上的通信是否成功。 // 如果 goroutine 在 channel c 上传了一个值而被唤醒，则为 true； // 如果因为 c 关闭而被唤醒，则为 false。 success bool parent *sudog // semaRoot 二叉树 waitlink *sudog // g.waiting 列表 or semaRoot waittail *sudog // semaRoot c *hchan // channel } 创建 Channel channel 的创建如下所示：\nch := make(chan int) 在编译阶段，编译器会讲上述代码转换成 OMAKE 类型的节点，并且在类型检查阶段将其转换为 OMAKECHAN 类型。\n// src/cmd/compile/internal/typecheck/typecheck.go func typecheck1(n ir.Node, top int) ir.Node { switch n.Op() { default: ir.Dump(\u0026#34;typecheck\u0026#34;, n) base.Fatalf(\u0026#34;typecheck %v\u0026#34;, n.Op()) panic(\u0026#34;unreachable\u0026#34;) // ... case ir.OMAKE: n := n.(*ir.CallExpr) return tcMake(n) // ... } } // src/cmd/compile/internal/typecheck/func.go func tcMake(n *ir.CallExpr) ir.Node { args := n.Args // ... i := 1 var nn ir.Node switch t.Kind() { default: base.Errorf(\u0026#34;cannot make type %v\u0026#34;, t) n.SetType(nil) return n // ... // channel 类型 case types.TCHAN: l = nil // 带缓冲 channel if i \u0026lt; len(args) { l = args[i] i++ l = Expr(l) l = DefaultLit(l, types.Types[types.TINT]) if l.Type() == nil { n.SetType(nil) return n } if !checkmake(t, \u0026#34;buffer\u0026#34;, \u0026amp;l) { n.SetType(nil) return n } } else { // 不带缓冲 channel l = ir.NewInt(0) } nn = ir.NewMakeExpr(n.Pos(), ir.OMAKECHAN, l, nil) } if i \u0026lt; len(args) { base.Errorf(\u0026#34;too many arguments to make(%v)\u0026#34;, t) n.SetType(nil) return n } nn.SetType(t) return nn } OMAKECHAN 类型的节点最终被转换为 调用 runtime.makechan 或runtime.makechan64 函数：\n// src/cmd/compile/internal/walk/expr.go func walkExpr1(n ir.Node, init *ir.Nodes) ir.Node { switch n.Op() { default: ir.Dump(\u0026#34;walk\u0026#34;, n) base.Fatalf(\u0026#34;walkExpr: switch 1 unknown op %+v\u0026#34;, n.Op()) panic(\u0026#34;unreachable\u0026#34;) case ir.OGETG, ir.OGETCALLERPC, ir.OGETCALLERSP: return n // ... case ir.OMAKECHAN: n := n.(*ir.MakeExpr) return walkMakeChan(n, init) // ... } } // src/cmd/compile/internal/walk/builtin.go func walkMakeChan(n *ir.MakeExpr, init *ir.Nodes) ir.Node { fnname := \u0026#34;makechan64\u0026#34; argtype := types.Types[types.TINT64] // 类型检查时如果 TIDEAL 大小在 int 范围内。 // 将 TUINT 或 TUINTPTR 转换为 TINT 时出现大小溢出的情况，将在运行时在 makechan 中进行检查。 if size.Type().IsKind(types.TIDEAL) || size.Type().Size() \u0026lt;= types.Types[types.TUINT].Size() { fnname = \u0026#34;makechan\u0026#34; argtype = types.Types[types.TINT] } return mkcall1(chanfn(fnname, 1, n.Type()), n.Type(), init, reflectdata.MakeChanRType(base.Pos, n), typecheck.Conv(size, argtype)) } 上述代码中，默认调用makechan64 函数。如果在 make 函数中传入的 channel size 大小在 int 范围内，推荐使用 makechan() 。因为 makechan() 在 32 位的平台上更快，用的内存更少。\n而runtime.makechan64 最终在判断了入参 size 是否在 int 范围之内后，也会转为runtime.makechan() 来执行，所以我们重点关注 runtime.makechan() 即可：\n// src/runtime/chan.go func makechan64(t *chantype, size int64) *hchan { if int64(int(size)) != size { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } return makechan(t, int(size)) } // src/runtime/chan.go func makechan(t *chantype, size int) *hchan { elem := t.elem // 检查数据项大小不能超过 64KB if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { throw(\u0026#34;makechan: invalid channel element type\u0026#34;) } // 检查对齐 if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { throw(\u0026#34;makechan: bad alignment\u0026#34;) } // 缓冲区大小检查 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) // 溢出判断 if overflow || mem \u0026gt; maxAlloc-hchanSize || size \u0026lt; 0 { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } // ... // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch { case mem == 0: // 不存在缓冲区 c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race 竞争检查利用这个地址来进行同步操作 c.buf = c.raceaddr() case elem.ptrdata == 0: // 元素非指针类型 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // 元素为指针类型 c = new(hchan) c.buf = mallocgc(mem, elem, true) } // 设置属性 c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) // lock 初始化 lockInit(\u0026amp;c.lock, lockRankHchan) return c } makechan() 代码主要的目的就是生成 *hchan 对象。在 switch-case 中有以下三种情况：\n当 channel 缓冲区大小为 0 时，会在堆上为 channel 开辟一段大小为 hchanSize 的内存空间。 当 channel 缓冲区中存储的元素不是指针类型时，会在堆上为当前 channel 和底层数组分配一段大小为 hchanSize + mem 的连续内存空间。 默认情况下，缓冲区元素类型为指针类型，会在堆上分别为 channel 和 缓冲区分配内存空间。 因为 channel 的创建全部调用 mallocgc() 实现，在堆上开辟了内存空间，channel 本身会被 GC 自动回收。完成内存分配之后，统一对 hchan 中的其他字段做初始化。\n发送数据 向 channel 中发送数据常见代码如下所示：\nch \u0026lt;- 1 在编译阶段，编译器会讲上述代码转换成 OSEND 类型的节点，并最终转换为对 runtime.chansend1() 的调用。\n// src/cmd/compile/internal/walk/expr.go func walkExpr1(n ir.Node, init *ir.Nodes) ir.Node { switch n.Op() { default: ir.Dump(\u0026#34;walk\u0026#34;, n) base.Fatalf(\u0026#34;walkExpr: switch 1 unknown op %+v\u0026#34;, n.Op()) panic(\u0026#34;unreachable\u0026#34;) // ... case ir.OSEND: n := n.(*ir.SendStmt) return walkSend(n, init) } // ... } // src/cmd/compile/internal/walk/expr.go func walkSend(n *ir.SendStmt, init *ir.Nodes) ir.Node { n1 := n.Value n1 = typecheck.AssignConv(n1, n.Chan.Type().Elem(), \u0026#34;chan send\u0026#34;) n1 = walkExpr(n1, init) n1 = typecheck.NodAddr(n1) return mkcall1(chanfn(\u0026#34;chansend1\u0026#34;, 2, n.Chan.Type()), nil, init, n.Chan, n1) } 而 runtime.chansend1() 只是调用了runtime.chansend()函数，并传入 channel 和需要发送的数据。\n// src/runtime/chan.go func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } 所以 channel 发送数据的核心实现在 runtime.chansend() 函数中，并且根据参数 block 直是否为 true 可知当前发送操作是否为阻塞的。由于runtime.chansend函数实现比较复杂，所以我们将它的代码拆为异常检查、同步发送、异步发送、阻塞发送 4 个部分进行分析。\n1. 异常检查 函数一开始先进行异常检查：\n// src/runtime/chan.go func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { // 是否阻塞 if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } if debugChan { print(\u0026#34;chansend: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } if raceenabled { racereadpc(c.raceaddr(), callerpc, abi.FuncPCABIInternal(chansend)) } // 非阻塞、channel未关闭且队列已满 if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; full(c) { return false } // 加锁 lock(\u0026amp;c.lock) // channel 已经关闭 if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } // ... } // src/runtime/chan.go func full(c *hchan) bool { // c.dataqsiz 是不可变的，任何时候都可以安全读取 if c.dataqsiz == 0 { return c.recvq.first == nil } return c.qcount == c.dataqsiz } 如果 channel 被 GC 回收会变为 nil，向一个 nil channel 同步发送数据会发生阻塞，gopark 会引发以 waitReasonChanSendNilChan 为原因的休眠，并且之后抛出 unreachable 的 fatal error. 然后，对非阻塞的发送，要检查 channel 是否未关闭以及channel 是否可以接收数据。其次，在发送数据之前，要对整个 channel 加锁，保证线程安全。并再一次检查 channel 是否关闭，如果关闭则抛出 panic。\n2. 同步发送 如果有正在阻塞等待的接收者，则直接从接收等待队列中取出第一个非空的 sudog ，并且调用send函数直接向其发送数据。\n// src/runtime/chan.go func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { //... if sg := c.recvq.dequeue(); sg != nil { send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } //... } send 函数具体实现如下：\n// src/runtime/chan.go func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // ... if sg.elem != nil { sendDirect(c.elemtype, sg, ep) sg.elem = nil } gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) sg.success = true if sg.releasetime != 0 { sg.releasetime = cputicks() } goready(gp, skip+1) } 函数执行可以分为 2 个部分：\n调用runtime.sendDirect() 函数，将数据直接复制到接收变量的内存地址上。 调用runtime.goready() 函数将等待接收的阻塞 goroutine 的状态改为 Grunnable ，并且把该 goroutine 放到发送方所在处理器 p 的 runnext 上等待执行，该处理器 p 下一次调度时会立刻唤醒数据的接收方。 其中，goready() 具体实现如下：\n// src/runtime/proc.go func goready(gp *g, traceskip int) { systemstack(func() { ready(gp, traceskip, true) }) } func ready(gp *g, traceskip int, next bool) { // ... // status is Gwaiting or Gscanwaiting, make Grunnable and put on runq casgstatus(gp, _Gwaiting, _Grunnable) runqput(mp.p.ptr(), gp, next) wakep() releasem(mp) } casgstatus()函数的作用是修改当前 goroutine 的状态，runqput 的作用是把接收方 g 绑定到 p 本地可运行的队列中，此处 next 为 true，就是将 g 插入到 runnext 中 ，等待下一次调度就可以立即运行。这样虽然 goroutine 保证了线程安全，但是在读取数据方面会比数组慢一些，也就是说向 channel 中发送数据后并不能立即从接收方获取到。\n3. 异步发送 如果创建的 channel 包含缓冲区，当接受者队列为空并且 channel 缓冲区中的数据没有装满时，就会执行异步发送的逻辑：\n// src/runtime/chan.go func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { //... if c.qcount \u0026lt; c.dataqsiz { qp := chanbuf(c, c.sendx) if raceenabled { racenotify(c, c.sendx, nil) } typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ unlock(\u0026amp;c.lock) return true } //... } 这里首先调用chanbuf() 计算下一个可以存储数据的位置，然后调用typedmemmove() 将发送的数据拷贝到缓冲区 buf 中。拷贝完成后，重新计算发送索引 sendx 以及 qcount 的值。这里 buf 是一个环形的数组，所以当 sendx 和 数组大小相等时，sendx 会重新回到数组开始的位置。\n4. 阻塞发送 当没有接受者可以处理 channel 中的数据，并且没有缓冲区或者缓冲区已满时，向 channel 中发送数据会被阻塞，具体执行的代码如下所示：\n// src/runtime/chan.go func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { //... if !block { unlock(\u0026amp;c.lock) return false } gp := getg() // @1 mysg := acquireSudog() // @2 mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil c.sendq.enqueue(mysg) // @3 gp.parkingOnChan.Store(true) // @4 gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // @5 KeepAlive(ep) // @6 // ... } 执行runtime.getg() 获取当前 goroutine 的指针，用于绑定给一个 sudog。 执行runtime.acquireSudog()获取一个 sudog（可能是新建的 sudog，也有可能是从缓存中获取的），并且设置此次发送的数据和状态，比如当前 goroutine 的指针，发送的 channel，是否在 select 中和带发送数据的内存地址等。 将刚刚获取并处理过的 sudog 加入到发送等待队列。 设置一个原子信号，声明当前 goroutine 还停在某个 channel 上面。在 g 状态变更与设 activeStackChans 状态这两个时间点之间的时间窗口进行栈收缩是不安全的，所以需要设置这个原子信号。 调用runtime.gopark()挂起当前 goruntine ，挂起原因为 waitReasonChanSend，阻塞等待 channel。 最后，调用KeepAlive()函数，确保发送的值保持活动状态，直到接收者将其复制出来。sudog有一个指向堆栈对象的指针，但 sudog 不被认为是堆栈追踪器的根。发送的数值是分配在堆上，这样就可以避免被 GC 回收。 chansend 最后的逻辑是当 goroutine 唤醒以后，解除阻塞的状态：\n// src/runtime/chan.go func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { //... if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) if closed { if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) } panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } return true } gorountine 被唤醒后，会完成对 channel 的阻塞数据发送，然后进行基本的数据检查，解除 channel 的绑定并调用releaseSudog()函数释放 sudog。\nchansend()函数最后返回 true，表示此次已经成功向 channel 发送了数据。\n5. 小结 对于向 channel 发送数据的代码已经完成分析，下面做一个小结：\n向已经关闭的 channel 中发送数据，会产生 panic。 如果当前 channel 的 recvq 上存在等待的 g，那么会直接将数据发送给当前 g 并且将其设置为下一个要被调度的 g。 如果 channel 存在未满的缓冲区，则直接将数据写入缓冲区 sendx 所在的位置。 如果不满足以上两种情况，则会获取一个 sudog 结构，并设置好其属性，将其加入 channel 的 sendq 等待队列中，挂起当前 goroutine ，等待缓冲区有位置或者有其他 goroutine 从 channel 中接收数据时被调度器唤醒。 发送数据的过程中包含了 2 次会触发 goroutine 调度的时机：\n当接收等待队列存在 sudog 可以直接接收数据时，执行goready() 函数，将接收等待队列的 goruntine 设置处理器的 runnext 属性，将其状态改为 Grunnable ，等待下次调度便立即运行。 当 channel 阻塞时，将自己加入 channel 的 sendq 发送等待队列，并执行 gopark() 函数，阻塞当前 gorountine，让出 cpu 的使用权。 接收数据 从 channel 中接收数据常见代码如下所示：\n// 将结果赋值给变量 v v := \u0026lt;-ch // comma ok 风格 v, ok := \u0026lt;-ch 在编译阶段，编译器会讲上述代码转换成 ORECV 类型的节点。第二种方式在类型检查阶段会被转换为 OAS2RECV 类型。 与上面发送数据源码分析方式类似，如下图所示，这两种类型首先会被转为对runtime.chanrecv1() 和 runtime.chanrecv2()的调用，并且最终转换为对runtime.chanrecv()的调用。\n// src/runtime/chan.go // go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } // go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } 所以 channel 发送数据的核心实现在 runtime.chanrecv() 函数中，并且根据参数 block 直是否为 true 可知当前发送操作是否为阻塞的，同样由于runtime.chanrecv()函数实现比较复杂，所以我们将它的代码拆为异常检查、同步接收、异步接收、阻塞接收 4 个部分进行分析。\n1.异常检查 runtime.chanrevc()函数一开始是进行异常检查：\n// src/runtime/chan.go func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { if debugChan { print(\u0026#34;chanrecv: chan=\u0026#34;, c, \u0026#34;\\n\u0026#34;) } if c == nil { if !block { return } // 阻塞模式，挂起等待 gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } // Fast path: check for failed non-blocking operation without acquiring the lock. // 非阻塞并且channel为空 if !block \u0026amp;\u0026amp; empty(c) { if empty(c) { // The channel is irreversibly closed and empty. if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } //... } // src/runtime/chan.go func empty(c *hchan) bool { // c.dataqsiz 是不可变的 if c.dataqsiz == 0 { return atomic.Loadp(unsafe.Pointer(\u0026amp;c.sendq.first)) == nil } return atomic.Loaduint(\u0026amp;c.qcount) == 0 } 如果 channel 被 GC 回收会变为 nil，从一个 nil channel 同步接收数据会发生阻塞，gopark 会引发以 waitReasonChanReceiveNilChan 为原因的休眠，并且之后抛出 unreachable 的 fatal error. 然后，对非阻塞的发送，要检查 channel 是否为空，如果 channel 为空，那么就会清除 ep 中的数据并且立即返回。这里总共检查了两次 empty()，因为第一次检查时， channel 可能还没有关闭，但是第二次检查的时候关闭了，在两次检查之间可能有待接收的数据到达了。所以需要两次 empty() 检查。\n2.同步接收 如果有正在阻塞等待的发送者，则直接从接收等待队列中取出第一个非空的 sudog ，并且调用recv函数直接向其发送数据。\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { lock(\u0026amp;c.lock) if c.closed != 0 { // 已关闭并且没有数据 if c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(\u0026amp;c.lock) if ep != nil { // 清除ep指针 typedmemclr(c.elemtype, ep) } return true, false } } else { // 未关闭，send queue中有等待的writer，writer出队，并调用recv函数 // Just found waiting sender with not closed. if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } } } runtime.recv() 函数的逻辑如下所示：\nfunc recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // 不带缓冲区 if c.dataqsiz == 0 { if raceenabled { racesync(c, sg) } if ep != nil { // copy data from sender recvDirect(c.elemtype, sg, ep) } } else { // 带缓冲区 qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) racenotify(c, c.recvx, sg) } // copy data from queue to receiver if ep != nil { typedmemmove(c.elemtype, ep, qp) } // copy data from sender to queue // 将 sender 的数据拷贝到这个槽中 typedmemmove(c.elemtype, qp, sg.elem) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz } sg.elem = nil gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) sg.success = true if sg.releasetime != 0 { sg.releasetime = cputicks() } goready(gp, skip+1) } 如果ch不带缓冲区的话，直接调用runtimne.recvDirect函数将 writer 的sg.elem数据拷贝到接收方 ep. 如果带缓冲区的话，此时缓冲区肯定满了，那么就从缓冲区队列头部取出数据拷贝至接收方 ep，然后将 writer 的sg.elem数据拷贝到缓冲区中。 最后唤醒 writer（g） 3.异步接收 当 channel 的缓冲区已经包含数据时，从 channel 中接收数据会直接从缓冲区 recv 的索引位置取出数据进行处理：\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // ... if c.qcount \u0026gt; 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(\u0026amp;c.lock) return true, true } // 不阻塞 if !block { unlock(\u0026amp;c.lock) return false, false } // ... } 如果接收数据的内存地址不为空，那么就会使用runtime.touedmemmove() 函数将缓冲区的数据复制到内存中，然后调用runtime.typedmemclr()函数清除队列中的数据，并且挪动 revcx 的指针位置（如果移动到了环形队列的队尾，下标需要回到队头），减少 count 计数器，并且释放掉占有的锁。\n4.阻塞接收 当 channel 的发送队列中不存在等待的 goroutine，并缺缓冲区也没有数据是，从 channel 中接收数据的操作就会进入阻塞接收的阶段：\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // 阻塞且缓冲区中没有数据 // 拿到当前的goroutine gp := getg() // @1 // 获取一个sudog mysg := acquireSudog() // @2 // sudog 关联 mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil // 入队 c.recvq.enqueue(mysg) // @3 // Signal to anyone trying to shrink our stack that we\u0026#39;re about // to park on a channel. The window between when this G\u0026#39;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. gp.parkingOnChan.Store(true) // @4 // 协程挂起，等待唤醒 gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // @5 } 执行runtime.getg() 获取当前 goroutine 的指针，用于绑定给一个 sudog。 执行runtime.acquireSudog()获取一个 sudog（可能是新建的 sudog，也有可能是从缓存中获取的），并且关联到当前的 guroutine。 将刚刚获取并处理过的 sudog 加入到接收等待队列。 设置一个原子信号，声明当前 goroutine 还停在某个 channel 上面。在 g 状态变更与设 activeStackChans 状态这两个时间点之间的时间窗口进行栈收缩是不安全的，所以需要设置这个原子信号。 调用runtime.gopark()挂起当前 goruntine ，挂起原因为waitReasonChanReceive，阻塞等待 channel。 上面这段代码与 chansend() 中阻塞发送几乎完全一致，区别在于最后一步没有 KeepAlive(ep)。因为等待的 goroutine ep 中是没有数据需要去保活的。\nchanrecv 最后的逻辑是当 goroutine 唤醒以后，解除阻塞的状态：\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil // sudog 解除关联 mysg.c = nil releaseSudog(mysg) return true, success } gorountine 被唤醒后，会完成对 channel 的阻塞数据接收。接收完最后进行基本的参数检查，解除 channel 的绑定并释放 sudog\n5.小结 对于从 channel 中接收数据的代码已经完成分析，下面做一个小结：\n从已经关闭的 channel 中读取数据，会直接返回 channel 中类型的默认零值。 如果当前 channel 的 sendq 上存在等待的 g，那么会将 recvx 索引所在的数据复制到接收变量所在的内存空间，并将 sendq 队列中 goroutine 中的数据复制到缓冲区。 如果 channel 缓冲区中包含数据，则直接读取recvx 索引对应的数据。 如果不满足以上两种情况，则会获取一个 sudog 结构，并设置好其属性，将其加入 channel 的 recvq 等待队列中，挂起当前 goroutine 等待调度器的唤醒。 接收数据的过程中包含了 2 次会触发 goroutine 调度的时机：\n当 channel 为 nil 时，执行gopark() 挂起当前 goroutine 当 channel 缓冲区为空，并且不存在发送者时，channel 发生阻塞，执行 gopark() 将 g 阻塞，让出 cpu 的使用权并等待调度器的调度。 关闭 Channel 关闭 channel 常见代码如下所示：\nclose(ch) 在编译阶段，编译器会讲上述代码转换成 OCLOSE 类型的节点，并且最终转换为对runtime.closechan()函数的调用：\nfunc closechan(c *hchan) { if c == nil { panic(plainError(\u0026#34;close of nil channel\u0026#34;)) } // 加锁 lock(\u0026amp;c.lock) if c.closed != 0 { // 已经关闭的channel unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, abi.FuncPCABIInternal(closechan)) racerelease(c.raceaddr()) } // 设置关闭标记位 c.closed = 1 // 1. 申明一个存放g的list，用于存放在等待队列中的groutine var glist gList // 2. 获取所有在recvq里面的协程 // release all readers for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // 3. 获取所有在sendq里面的协程 // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026amp;c.lock) // Ready all Gs now that we\u0026#39;ve dropped the channel lock. // 4.唤醒所有的glist中的goroutine for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } 关闭 channel 的过程主要可以分为以下几个阶段：\n异常检查：当 Channel 是一个 nil 或者是一个已经关闭的 channel 时，会发生 panic。 分别获取 recvq 和 sendq 中的 goroutine，一并放入 glist 队列中。 唤醒 glist 中的所有 goroutine，等待调度器的调度。 参考资料 Communicating sequential processes Go 语言设计与实现 深入 Go 并发原语 — Channel 底层实现 ","permalink":"https://yanhuan0802.github.io/en/posts/explore-go-channel/","summary":"Channel 是 Go 语言的核心数据结构，也是支撑 Go 高性能并发编程的重要结构。在本篇文章中，我们将从 channel 的设计原理、数据结构、发送数据、接收数据以及关闭 channel 这几","title":"深入理解 Go Channel 底层实现"},{"content":"数组array和切片slice是 Go 语言的两种基本数据结构，也是我们需要深入了解的基础概念。在本篇文章中，我们将深入探讨 Go 语言的数组和切片实现原理，帮助大家更好地理解它们的使用方法和优劣势。\n本文源码基于 Go 1.20\n数组 数据结构 数组是计算机科学中的一种数据结构，它具有以下几个特点：\n元素类型相同，存储宽度一致 存储在一段连续的内存空间 空间大小固定，不能修改（会出现数据溢出问题） 可以通过元素索引计算出元素的存储地址 几乎所有的计算机语言，对于数组的实现都是相似的，都拥有上述特性，Go语言也一样。\n不同于 C 语言或其他语言，Go 语言数组是值类型，定义的时候就需要指定大小，数组大小是它类型的一部分，不同大小的数组相当于不同的类型，赋值和函数传参都会复制整个数组，相当于是原数组的拷贝。\n初始化 数组有两种初始化的方式，一种是显示声明数组的长度，一种是使用[...]T声明数组。\narr1 := [3]int{0, 1, 2} arr2 := [...]int{0, 1, 2} 第二种初始化的方式属于 Go 语言提供的语法糖，在编译期间就会推导出数组的长度，最终转换成第一种，所以上述两种声明方式在运行期间得到的结果是相同的。\n在编译期间，Go 会根据数组的元素数量，做出如下的优化：\n当元素小于等于4个时，会直接将数组的元素在栈上面初始化； 当元素大于4个时，会将数组在静态区初始化然后复制到栈上面。 缺点 数组大小是固定的，但是很多场景中我们无法直接给出数组的确定长度。\n数组是值类型，传递一个很大的数组给函数会消耗很多内存。\n切片 由于数组的固定长度和值传递不够灵活，所以 Go 语言中，拥有不定长度的引用类型切片（slice）更加常用。\n切片是对数组一个连续片段的引用，这些片段可以是整个数组，或者是由其实和终止索引表示的一些项的子集。\n数据结构 切片的数据结构在源码包中定义\n// src/runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针 len int // 长度 cap int // 容量 } 其中，array表示指向相关数组的指针，len表示切片长度，cap表示当前切片的容量，即底层数组的大小。其中底层数组是可以被多个 slice 同时指向的，所以对一个 slice 中的元素进行操作，可能也会影响到其他slice.\n由于切片结构体中直接存储了切片的长度和容量，所以内置函数len()和cap()操作的时间复杂度均为O(1).\n切片在运行时的表示:\n// src/reflect/value.go // Deprecated: Use unsafe.Slice or unsafe.SliceData instead. type SliceHeader struct { Data uintptr Len int Cap int } // go 1.20 src/unsafe/unsafe.go // SliceData returns a pointer to the underlying array of the argument // slice. // - If cap(slice) \u0026gt; 0, SliceData returns \u0026amp;slice[:1][0]. // - If slice == nil, SliceData returns nil. // - Otherwise, SliceData returns a non-nil pointer to an // unspecified memory address. func SliceData(slice []ArbitraryType) *ArbitraryType 初始化 变量声明 var s []int 使用这种方式创建出来的 slice 是变量零值，即 nil。它的长度和容量都是 0 ，和nil相等。nil切片可以通过append函数来完成内存申请和元素追加。\n字面量 s1 := []int{} // 空切片 s2 := []int{1, 2} // 长度为3的切片 s3 := []int{0, 1, 2, 3, 8: 100} // 使用索引号直接复制，将索引为 8 位置的元素赋值为 100 其中，空切片指的是切片长度为 0 ，但是值并不是nil，声明长度为 0 的切片时，尽量使用nil切片，这样就不需要进行内存分配。\nmake 函数 s1 := make([]int, 10) // 指定长度，此时容量默认和长度相等 s2 := make([]int, 10, 30) //指定长度和容量 创建时，底层会分配一个数组，数组的长度就是切片的容量。\n创建切片时的运行运行时函数如下：\n// src/runtime/slice.go func makeslice(et *_type, len, cap int) unsafe.Pointer { // 内存空间 = 元素大小 * 切片容量 mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // panic 条件 // 1.内存空间溢出 // 2.申请的内存空间大于最大可分配的内存 // 3.长度小于 0 或大于容量 if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() } panicmakeslicecap() } // 内存申请：小对象在 P 结构中初始化，大于 32KB 在堆中初始化 return mallocgc(mem, et, true) } 通过下标从数组或切片中切取 s1 := array[1:5] s2 := sourceSlice[1:5] 使用下标初始化不会复制原数组或者原切片中的数据，只会创建一个指向原数组的结构体，数组后面的内容都作为切片的预留内存。 同时，slice 将和原数组共用一部分内存，对数组或slice元素的修改，都会影响到彼此。如果因为执行append操作使得新的 slice 底层数组扩容，移动到了新的位置，那么两者就不会互相影响了。\n追加和扩容 追加 使用 append函数可以向切片中追加元素：\nfunc append(slice []Type, elems ...Type) []Type append函数的参数长度可变，所以可以追加多个值到 slice 中，还可以用 ...传入 slice，直接追加一个切片。\ns1 = append(s1, 1, 2, 3) s1 = append(s1, s2...) append函数返回值是一个新的 slice，可以选择覆盖原 slice，也可以选择定义赋值给新的 slice，但是 Go 编译器不允许调用了 append函数后不使用返回值。\n扩容 使用append向 slice 中追加元素，实际上是向底层数组添加元素，如果 slice 底层数组空间不足，就会触发 slice 扩容。\n扩容就是为切片分配新的内存空间并复制原切片中元素的过程。新的底层数组长度大于原有的 slice 底层数组，这样就可以进行append操作，具体的扩容策略如下：\n// src/runtime/slice.go func growslice(oldPtr unsafe.Pointer, newLen, oldCap, num int, et *_type) slice { ... // 扩容策略 newcap := oldCap doublecap := newcap + newcap if newLen \u0026gt; doublecap { // 期望大小大于当前容量的两倍，使用期望大小 newcap = newLen } else { // 期望大小小于当前容量的两倍 const threshold = 256 if oldCap \u0026lt; threshold { // 原容量小于 256 ，容量翻倍 newcap = doublecap } else { // 原容量大于256 // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. // 保证 newcap \u0026gt; newLen for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; newLen { // Transition from growing 2x for small slices // to growing 1.25x for large slices. This formula // gives a smooth-ish transition between the two. // 每次增加 25% + 192，比 Go1.18 之前更加平滑 newcap += (newcap + 3*threshold) / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. // 溢出情况处理 if newcap \u0026lt;= 0 { newcap = newLen } } } ... } 在运行时，根据新长度的大小，选择了不同的策略进行扩容：\n如果期望大小大于当前容量的两倍，新容量就会使用期望大小 否则判断，如果旧切片的容量小于 256，新容量就会是旧容量的两倍 否则判断，如果旧切片的容量大于256，新容量就会使用从旧容量开始循环增加，每次增加25% + 192，直到新容量大于等于新长度。 如果新容量计算溢出了，就使用新长度作为新容量。 这个扩容策略是在 Go 1.18 开始执行的，相比 Go 1.18 之前使用 1024 作为扩容基准值，这个策略则更加平滑。\n经过上述策略，得到的新容量只能说是一个大致容量，最终的容量和内存大小，还需要根据切片中的元素大小进行内存对齐。具体内存对齐代码如下所示：\n// src/runtime/slice.go func growslice(oldPtr unsafe.Pointer, newLen, oldCap, num int, et *_type) slice { ... // 新长度及容量大小计算，根据切片中元素大小进行内存对齐 var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don\u0026#39;t need any division/multiplication. // For goarch.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. switch { case et.size == 1: lenmem = uintptr(oldLen) newlenmem = uintptr(newLen) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u0026gt; maxAlloc newcap = int(capmem) case et.size == goarch.PtrSize: lenmem = uintptr(oldLen) * goarch.PtrSize newlenmem = uintptr(newLen) * goarch.PtrSize capmem = roundupsize(uintptr(newcap) * goarch.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/goarch.PtrSize newcap = int(capmem / goarch.PtrSize) case isPowerOfTwo(et.size): var shift uintptr if goarch.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.TrailingZeros64(uint64(et.size))) \u0026amp; 63 } else { shift = uintptr(sys.TrailingZeros32(uint32(et.size))) \u0026amp; 31 } lenmem = uintptr(oldLen) \u0026lt;\u0026lt; shift newlenmem = uintptr(newLen) \u0026lt;\u0026lt; shift capmem = roundupsize(uintptr(newcap) \u0026lt;\u0026lt; shift) overflow = uintptr(newcap) \u0026gt; (maxAlloc \u0026gt;\u0026gt; shift) newcap = int(capmem \u0026gt;\u0026gt; shift) capmem = uintptr(newcap) \u0026lt;\u0026lt; shift default: lenmem = uintptr(oldLen) * et.size newlenmem = uintptr(newLen) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) capmem = uintptr(newcap) * et.size } ... } // src/runtime/msize.go func roundupsize(size uintptr) uintptr { if size \u0026lt; _MaxSmallSize { if size \u0026lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[divRoundUp(size, smallSizeDiv)]]) } else { return uintptr(class_to_size[size_to_class128[divRoundUp(size-smallSizeMax, largeSizeDiv)]]) } } if size+_PageSize \u0026lt; size { return size } return alignUp(size, _PageSize) } // src/runtime/sizeclass.go const ( _MaxSmallSize = 32768 smallSizeDiv = 8 smallSizeMax = 1024 largeSizeDiv = 128 _NumSizeClasses = 68 _PageShift = 13 ) // 这是 Go 源码中有关内存分配的 slice。 // class_to_size 通过 spanClass获取 span划分的 object大小。 // 而 size_to_class8 size_to_class128 表示通过 size 获取它的 spanClass var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 24, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} var size_to_class8 = [smallSizeMax/smallSizeDiv + 1]uint8{0, 1, 2, 3, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32} var size_to_class128 = [(_MaxSmallSize-smallSizeMax)/largeSizeDiv + 1]uint8{32, 33, 34, 35, 36, 37, 37, 38, 38, 39, 39, 40, 40, 40, 41, 41, 41, 42, 43, 43, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 48, 48, 48, 49, 49, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 54, 54, 54, 54, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67} // src/runtime/stubs.go func divRoundUp(n, a uintptr) uintptr { // a is generally a power of two. This will get inlined and // the compiler will optimize the division. return (n + a - 1) / a } rounddupsize函数会将待申请的内存向上取整，取整时会使用class_to_size数组，提高了内存分配效率并减少碎片。\n接下来，就是进行内存分配，复制数据，append元素到新的底层数组。\n// src/runtime/slice.go func growslice(oldPtr unsafe.Pointer, newLen, oldCap, num int, et *_type) slice { ... // 计算内存溢出 if overflow || capmem \u0026gt; maxAlloc { panic(errorString(\u0026#34;growslice: len out of range\u0026#34;)) } var p unsafe.Pointer if et.ptrdata == 0 { // 切片中的元素不是指针类型 // 分配内存 p = mallocgc(capmem, nil, false) // 清除不会覆盖的部分 memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // 切片中的元素是指针类型 // 分配内存 p = mallocgc(capmem, et, true) if lenmem \u0026gt; 0 \u0026amp;\u0026amp; writeBarrier.enabled { // 内存屏障 bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(oldPtr), lenmem-et.size+et.ptrdata) } } // 复制原数组内存中的内容到新申请的内存中 memmove(p, oldPtr, lenmem) return slice{p, newLen, newcap} } 此外，nil切片和空切片都是可以通过调用append函数来获得底层数组的扩容，最终都是通过mallocgc来进行内存申请，再赋值给原来的nil切片或空切片，所以nil切片是可以调动append函数的。\n我们用一个常见的例子总结一下扩容的过程\nfunc main() { s := []int{1, 2} s = append(s, 3, 4, 5) fmt.Printf(\u0026#34;len=%d, cap=%d\u0026#34;,len(s), cap(s)) } 程序运行结果为：\nlen = 5, cap = 6 在上述代码执行的过程中，我们先初始化了一个长度和容量均为 2 的切片 s ，然后向 s 中追加三个元素，此时就会触发扩容，期望大小为 5，5 大于当前容量的两倍，所以初步计算的 newcap 为 5，在 64 位机器上一个指针的大小为 8 字节，所以期望分配的内存大小为 40 字节。然后要进行内存对齐计算，调用roundupsize进行向上取整，计算结果如下所示：\n// capmem 计算公式 class_to_size[size_to_class8[divRoundUp(size, smallSizeDiv)]] divRoundUp(40, 8) = 5 size_to_class8[5] = 5 capmem = class_to_size[5] = 48 // newcap 计算 newcap = int(capmem / goarch.PtrSize) = 48/8 = 6 所以，最终新的 slice 容量为 6.\n拷贝 使用copy函数可以进行切片的拷贝操作，具体实现如下所示：\n// src/runtime/slice.go // 元素类型为string 或者 无指针 元素切片copy func slicecopy(toPtr unsafe.Pointer, toLen int, fromPtr unsafe.Pointer, fromLen int, width uintptr) int { // 如果长度为0，不需要 copy if fromLen == 0 || toLen == 0 { return 0 } // 记录源切片或者目标切片中较短的长度 n := fromLen if toLen \u0026lt; n { n = toLen } // 元素类型宽度为0，也不需要执行 copy 操作，直接返回短切片的长度 if width == 0 { return n } // 计算大小 size := uintptr(n) * width ... if size == 1 { // common case worth about 2x to do here // TODO: is this still worth it with new memmove impl? // 如果 size 大小为1，那么指针直接转换即可 *(*byte)(toPtr) = *(*byte)(fromPtr) // known to be a byte pointer } else { // 使用 memmove 将 size 大小的内存复制到目标区域 memmove(toPtr, fromPtr, size) } return n } // src/runtime/mbarrier.go // 指针类型的元素切片 copy func typedslicecopy(typ *_type, dstPtr unsafe.Pointer, dstLen int, srcPtr unsafe.Pointer, srcLen int) int { // copy 长度计算 n := dstLen if n \u0026gt; srcLen { n = srcLen } if n == 0 { return 0 } ... if writeBarrier.cgo { cgoCheckSliceCopy(typ, dstPtr, srcPtr, n) } // 指针相等，不需要copy了 if dstPtr == srcPtr { return n } // 内存大小计算 size := uintptr(n) * typ.size if writeBarrier.needed { pwsize := size - typ.size + typ.ptrdata bulkBarrierPreWrite(uintptr(dstPtr), uintptr(srcPtr), pwsize) } // 内存 copy memmove(dstPtr, srcPtr, size) return n } 上述代码分别是 string 及 元素无指针类型 切片以及指针类型元素切片的拷贝，其实现方法是类似的，即\n拷贝长度为两个切片长度的最小值 拷贝内容为源切片中对应拷贝长度的整块内存的内容 返回值为被拷贝的元素的个数 由此也可以得出，在拷贝的过程中，不会发生扩容。\n此外，在 range遍历的过程中，获得的 value 其实是切片中的值拷贝，并且每次都是拷贝到同一个地址，所以在遍历中拿到的 value 的地址是不变的，如下所示：\nfunc main() { slice := []int{10, 20, 30, 40} for index, value := range slice { fmt.Printf(\u0026#34;value = %d , value-addr = %x , slice-addr = %x\\n\u0026#34;, value, \u0026amp;value, \u0026amp;slice[index]) } } 输出结果：\nvalue = 10, value-addr = 14000126008, slice-addr = 1400012e000 value = 20, value-addr = 14000126008, slice-addr = 1400012e008 value = 30, value-addr = 14000126008 , slice-addr = 1400012e010 value = 40 , value-addr = 14000126008, slice-addr = 1400012e018 参数传递 首先，我们必须明确一点，Go 语言中的函数参数传递，只有值传递，没有引用传递。\n下面我们举几个例子来看看 slice 在函数参数传递中的一些细节。\nslice 和 slice 指针 代码示例：\nfunc Append(s []int) { s = append(s, 100) fmt.Printf(\u0026#34;param s: %v \\n \u0026#34;, s) } func AppendPtr(s *[]int) { *s = append(*s, 200) fmt.Printf(\u0026#34;param *s: %v \\n \u0026#34;, *s) } func main() { s1 := []int{1, 1, 1} Append(s1) fmt.Printf(\u0026#34;main s1: %v \\n \u0026#34;, s1) s2 := []int{1, 2, 3} AppendPtr(\u0026amp;s2) fmt.Printf(\u0026#34;main *s2: %v \\n \u0026#34;, s2) } 程序运行结果为：\nparam s: [1 1 1 100] main s1: [1 1 1] param *s: [1 2 3 200] main *s2: [1 2 3 200] 可以看出，在Append函数中，参数为 slice 值，所以对参数的变更，并不会影响到外层的 s.\n但是，将 s 指针传入AppendPtr，在函数中对参数做出的改变，是会影响到外层的 s.\nslice append 操作 代码示例：\nfunc SliceRise(s []int) { s = append(s, 0) for i := range s { s[i]++ } } func main() { s1 := []int{1, 2} s2 := s1 s2 = append(s2, 3) SliceRise(s1) SliceRise(s2) fmt.Println(s1, s2) } 程序运行结果为：\n[1 2] [2 3 4] 首先，SliceRise()函数中 slice 作为参数，是一个值传递，函数调用时，会拷贝原 slice 的值，对于值的修改不会影响外层的 slice。\n对于 s1 来说，底层数组本身的长度和容量均为2，传递进函数后，进行了 append 操作，这个 append 操作会引发切片的扩容，扩容后会产生一个新的底层数组，这个数组继续赋值给了变量 s。 此时，s1 和 s 指向的底层数组就不一样了，所以 s1 本身和它指向的底层数组，都没有发生任何变化，打印 s1 的结果仍然是 1 2.\n对于 s2 来说，最初 s2 和 s1 指向同一个底层数组，进行 append 操作之后，发生了扩容，并且将 append 之后的新切片赋值给了 s2， 到这里，s1 和 s2 就指向不同的底层数组了。 s2 传递进函数后，进行了 append 操作，这个 append 操作不会引发切片的扩容，这个数组继续赋值给了变量 s。 此时，s2 和 s 依旧共享底层数组，但是s 的长度 len 变成 4 了，而由于函数参数值传递的特点，s2 的长度 len 并不会被改变，所以在进行遍历对元素进行操作之后， 虽然对于 s 和底层数组来说，值变成了2 3 4 1，但是对于 s2 来说，它的长度是 3，所以打印 s2 的结果会是2 3 4.\n总结 数组存储的是一组元素类型相同，存储宽度一致的元素，它们存储在一段连续的内存空间，Go 中的数组是值类型，并且数组大小是固定的。 切片是对底层数组的一个抽象，表述的是对数组一个连续片段的引用。 切片结构体中包含了长度，容量以及底层数组地址，多个切片可以共享同一个底层数组。 append函数可以向切片中追加元素，并生成一个新的切片。当切片容量不足的情况下，append函数会先调用growslice进行扩容，然后再进行元素的追加。 切片扩容后容量的计算分为按照策略计算和内存对齐两部分。扩容后的容量 \u0026gt;= 原容量的两倍 或 1.25倍。 切片作为函数参数时是值传递，在函数中操作切片时，可能改变切边中的元素，但是不会改变切片本身。 参考资料 Go 语言设计与实现 Go 专家编程 深度解密 Go 语言之 slice 深入解析 Go 中 Slice 底层实现 【Go】深入剖析slice和array ","permalink":"https://yanhuan0802.github.io/en/posts/explore-go-array-slice/","summary":"数组array和切片slice是 Go 语言的两种基本数据结构，也是我们需要深入了解的基础概念。在本篇文章中，我们将深入探讨 Go 语言的数组和切片实现","title":"深入理解 Go 数组和切片底层实现"},{"content":"环境准备 准备一台 linux 物理机 安装对应的 packer 软件 安装对应的 qemu kvm 软件 镜像构建 分别将以下 hcl 文件以及 user-data 文件放置在提前准备好的目录当中\nPacker Hcl 文件 packer { required_version = \u0026#34;\u0026gt;= 1.7.0, \u0026lt; 2.0.0\u0026#34; required_plugins { qemu = { source = \u0026#34;github.com/hashicorp/qemu\u0026#34; version = \u0026#34;\u0026gt;= 1.0.0, \u0026lt; 2.0.0\u0026#34; } } } variable \u0026#34;vm_name\u0026#34; { type = string default = \u0026#34;ubuntu-2004.qcow2\u0026#34; } source \u0026#34;qemu\u0026#34; \u0026#34;test\u0026#34; { iso_url = \u0026#34;https://releases.ubuntu.com/20.04/ubuntu-20.04.5-live-server-amd64.iso\u0026#34; iso_checksum = \u0026#34;5035be37a7e9abbdc09f0d257f3e33416c1a0fb322ba860d42d74aa75c3468d4\u0026#34; vm_name = var.vm_name output_directory = \u0026#34;output\u0026#34; http_directory = \u0026#34;http\u0026#34; boot_wait = \u0026#34;2s\u0026#34; boot_command = [ \u0026#34;\u0026lt;esc\u0026gt;\u0026lt;esc\u0026gt;\u0026lt;esc\u0026gt;\u0026#34;, \u0026#34;\u0026lt;enter\u0026gt;\u0026lt;wait\u0026gt;\u0026#34;, \u0026#34;/casper/vmlinuz \u0026#34;, \u0026#34;initrd=/casper/initrd \u0026#34;, \u0026#34;autoinstall ds=nocloud-net;s=http://{{.HTTPIP}}:{{.HTTPPort}}/\u0026#34;, \u0026#34;\u0026lt;enter\u0026gt;\u0026#34; ] shutdown_command = \u0026#34;echo \u0026#39;packer\u0026#39; | sudo -S shutdown -P now\u0026#34; headless = true format = \u0026#34;qcow2\u0026#34; accelerator = \u0026#34;kvm\u0026#34; qemu_binary = \u0026#34;/usr/libexec/qemu-kvm\u0026#34; qemu_img_args { convert = [ \u0026#34;-m\u0026#34;, \u0026#34;8\u0026#34; ] } ssh_username = \u0026#34;root\u0026#34; ssh_password = \u0026#34;Root123!\u0026#34; ssh_timeout = \u0026#34;30m\u0026#34; vnc_bind_address = \u0026#34;0.0.0.0\u0026#34; cpus = 8 memory = 8192 net_device = \u0026#34;virtio-net\u0026#34; disk_size = \u0026#34;100G\u0026#34; disk_compression = true } build { name = \u0026#34;ubuntu20-04\u0026#34; sources = [ \u0026#34;source.qemu.test\u0026#34; ] provisioner \u0026#34;shell\u0026#34; { pause_before = \u0026#34;20s\u0026#34; inline = [\u0026#34;echo \u0026#39;build success\u0026#39;\u0026#34;] } } Ubuntu auto install user-data 文件 #cloud-config autoinstall: version: 1 early-commands: - hostnamectl set-hostname ubuntu # update hostname even for the installer environment - dhclient # re-register the updated hostname identity: # hostname of the system hostname: ubuntu # root doesn\u0026#39;t work username: ubuntu # ubuntu password: \u0026#34;$6$FhcddHFVZ7ABA4Gi$MhQrLRAMZI65UOGGwxyCYRgolj13tIHC3/MRfyQQlP4nD9jgIdn63Ol2qlO3I8I/Gfdcsg7k58dTYOzz3LeqJ.\u0026#34; ssh: install-server: true allow-pw: true user-data: timezone: Asia/Shanghai disable_root: false ssh_pwauth: true users: - name: root lock_passwd: false plain_text_passwd: Root123! - name: ubuntu lock_passwd: false plain_text_passwd: Root123! sudo: ALL=(ALL) NOPASSWD:ALL network: version: 2 ethernets: zz-all-en: match: name: \u0026#34;en*\u0026#34; dhcp4: true dhcp-identifier: mac zz-all-eth: match: name: \u0026#34;eth*\u0026#34; dhcp4: true dhcp-identifier: mac keyboard: layout: en variant: us locale: en_US storage: swap: size: 0 layout: name: direct packages: - bc - cloud-init - git - curl - wget - openssl - vim late-commands: - sed -i -e \u0026#39;s/^#\\?PasswordAuthentication.*/PasswordAuthentication yes/g\u0026#39; /target/etc/ssh/sshd_config - sed -i -e \u0026#39;s/^#\\?PermitRootLogin.*/PermitRootLogin yes/g\u0026#39; /target/etc/ssh/sshd_config - sed -i \u0026#39;s/^#*\\(send dhcp-client-identifier\\).*$/\\1 = hardware;/\u0026#39; /etc/dhcp/dhclient.conf - echo \u0026#39;ubuntu ALL=(ALL) NOPASSWD:ALL\u0026#39; \u0026gt; /target/etc/sudoers.d/ubuntu - curtin in-target --target=/target -- chmod 440 /etc/sudoers.d/ubuntu 执行 Packer 打包命令 packer build qemu.pkr.hcl 参考资料 Install Packer Ubuntu Automatic installation ","permalink":"https://yanhuan0802.github.io/en/posts/packer-qemu-ubuntu2004/","summary":"环境准备 准备一台 linux 物理机 安装对应的 packer 软件 安装对应的 qemu kvm 软件 镜像构建 分别将以下 hcl 文件以及 user-data 文件放置在提前准备好的目录当中 Packer Hcl 文件 packer { required_version = \u0026#34;\u0026gt;= 1.7.0, \u0026lt;","title":"使用 Packer QEMU 插件构建自定义 Ubuntu 20.04 OS 镜像"},{"content":" 本文介绍基于 kubeadm + 内地网络 进行 k8s 集群部署。 本文介绍搭建单 master 节点 k8s 集群，适用于开发及测试，一般不适用生产环境。 环境准备 主机配置要求 k8s 集群要求机器最低配置为 2CPU 2GRAM 关闭防火墙、交换分区、selinux # 防火墙 systemctl status firewalld # 如果没有firewalld.service，执行如下命令 sudo ufw status sudo ufw disable # 关闭swap swapoff -a cat /etc/fstab | grep swap # 删除或注释掉带有swap关键字的行 vi /etc/fstab # selinux # 检查 结果为Disabled即为关闭状态 apt update -y apt install -y selinux-utils getenforce # 如果selinux是启用状态，则需要永久关闭，关闭后重启机器方可生效 sed -i \u0026#39;s/SELINUX=enforcing/SELINUX=disabled/\u0026#39; /etc/selinux/config reboot 应用安装 安装容器运行时（CR） 自 1.24 版起，Dockershim 已从 Kubernetes 项目中移除，本文只介绍 containerd 的安装。 允许 iptables 检查桥接流量 # 确保overlay br_netfilter内核模块加载 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter # 为了Linux 节点上的 iptables 能够正确地查看桥接流量，需要确保在sysctl 配置中将 net.bridge.bridge-nf-call-iptables 设置为 1 # 设置所需的 sysctl 参数，参数在重新启动后保持不变 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF # 应用 sysctl 参数而不重新启动 sudo sysctl --system containerd安装 安装 apt repository # 删除旧版本（如果存在的话） sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update -y sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release software-properties-common sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null 安装 containerd sudo apt-get update -y sudo apt-get install containerd.io=1.6.20-1 配置 containerd sudo mkdir -p /etc/containerd containerd config default | sudo tee /etc/containerd/config.toml # 设置SystemdCgroup sudo sed -i \u0026#39;s/SystemdCgroup = false/SystemdCgroup = true/g\u0026#39; /etc/containerd/config.toml # 修改pause镜像地址 sudo sed -i \u0026#39;s/registry.k8s.io/registry.aliyuncs.com\\/google_containers/g\u0026#39; /etc/containerd/config.toml sudo systemctl restart containerd 配置镜像加速 mkdir -p /etc/containerd/certs.d/docker.io sed -i \u0026#39;s/\\(config_path *= *\\)\u0026#34;[^\u0026#34;]*\u0026#34;/\\1\u0026#34;\\/etc\\/containerd\\/certs.d\u0026#34;/\u0026#39; /etc/containerd/config.toml cat \u0026gt; /etc/containerd/certs.d/docker.io/hosts.toml \u0026lt;\u0026lt; EOF server = \u0026#34;https://docker.io\u0026#34; [host.\u0026#34;https://9ptmljtk.mirror.aliyuncs.com\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;] EOF sudo systemctl restart containerd 安装 crictl VERSION=\u0026#34;v1.25.0\u0026#34; wget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz sudo tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin rm -f crictl-$VERSION-linux-amd64.tar.gz 设置运行时，crictl 默认连接到 unix:///var/run/dockershim.sock，我们需要将其改为 containerd 的 socket # 配置 sudo crictl config runtime-endpoint unix:///run/containerd/containerd.sock sudo crictl config image-endpoint unix:///run/containerd/containerd.sock # 检查结果 cat /etc/crictl.yaml 安装kubeadm、kubelet 和 kubectl 在使用的机器上面都需要安装以下软件包 kubeadm：用来初始化集群的指令。 kubelet：在集群中的每个节点上用来启动 Pod 和容器等。 kubectl：用来与集群通信的命令行工具。 更新包索引、安装必要软件 sudo apt-get update -y sudo apt-get install -y apt-transport-https ca-certificates curl 从阿里镜像仓库下载密钥（无网络限制的话可以从 google 地址下载） sudo curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - 添加 k8s apt 仓库（无网络限制的话可以添加为 google 地址） sudo tee /etc/apt/sources.list.d/kubernetes.list \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main EOF 更新包索引，安装 kubelet、kubeadm 和 kubectl，并锁定其版本 # 旧版本清理 sudo apt remove -y kubeadm kubelet kubectl sudo apt autoremove -y # 安装 sudo apt-get update -y sudo apt-get install -y kubelet=1.26.4-00 kubeadm=1.26.4-00 kubectl=1.26.4-00 sudo apt-mark hold kubelet kubeadm kubectl 集群初始化 kubeadm init kubeadm config: 初始化配置文件，指定 apiServer endpoint 等地址 cat \u0026gt; /etc/kubernetes/config.yaml \u0026lt;\u0026lt; EOF apiVersion: kubeadm.k8s.io/v1beta3 kind: InitConfiguration nodeRegistration: criSocket: \u0026#34;unix:///run/containerd/containerd.sock\u0026#34; taints: [ ] imagePullPolicy: \u0026#34;IfNotPresent\u0026#34; localAPIEndpoint: # 公布 apiServer 正在监听的 IP 地址，需要替换为自己主机的 ip 地址 advertiseAddress: \u0026#34;10.10.98.36\u0026#34; bindPort: 6443 skipPhases: # 如果安装的网络插件为cilium, 可跳过 kube-proxy 的安装, 因为 cilium 内置 Host-Reachable Services 功能可以替换 kube-proxy - addon/kube-proxy --- apiVersion: kubeadm.k8s.io/v1beta3 kind: ClusterConfiguration kubernetesVersion: 1.26.4 # 公布 apiServer 正在监听的 IP 地址，需要替换为自己主机的 ip 地址 controlPlaneEndpoint: \u0026#34;10.10.98.36:6443\u0026#34; certificatesDir: \u0026#34;/etc/kubernetes/pki\u0026#34; imageRepository: \u0026#34;registry.aliyuncs.com/google_containers\u0026#34; EOF kubeadm init kubeadm init --config /etc/kubernetes/config.yaml 如果此步骤出错可运行kubeadm reset --force重置kubeadm状态，然后进行检查。 使非 root 用户可以运行 kubectl mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config root用户 export KUBECONFIG=/etc/kubernetes/admin.conf 默认情况下，出于安全原因，你的集群不会在控制平面节点上调度 Pod。 如果你希望能够在控制平面节点上调度 Pod， 例如用于开发的单机 Kubernetes 集群，请运行： kubectl taint nodes --all node-role.kubernetes.io/control-plane- 安装 helm 安装 k8s 包管理工具 helm，后续可以使用 helm 来进行应用安装。 curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg \u0026gt; /dev/null sudo apt-get install apt-transport-https --yes echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main\u0026#34; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list sudo apt-get update sudo apt-get install helm 安装网络插件 你必须部署一个基于 Pod 网络插件的容器网络接口 (CNI)，以便你的 Pod 可以相互通信。 在安装网络之前，集群 DNS (CoreDNS) 将不会启动。\n每个集群只能安装一中 Pod 网络插件。\n常见的pod网络插件有 Calico、Flannel、Cilium 等，本文以 Cilium 插件安装做示例，其余两种插件安装可参考对应的官网。\nCilium\n# add helm repo helm repo add cilium https://helm.cilium.io/ # helm install API_SERVER_IP=10.10.98.36 API_SERVER_PORT=6443 helm upgrade --install cilium cilium/cilium \\ --namespace kube-system \\ --version 1.13.1 \\ --set kubeProxyReplacement=strict \\ --set k8sServiceHost=${API_SERVER_IP} \\ --set k8sServicePort=${API_SERVER_PORT} \\ --set operator.replicas=1 ### 参数说明 kubeProxyReplacement: cilium agent是否在底层 Linux 内核支持缺失的情况下退出, 没有安装 kube-proxy 的情况下配置 strict, 表示内核不支持的话就退出. k8sServiceHost: apiserver ip k8sServicePort: apiserver port 由于每个人使用的机器网络状况不一样，所以安装网络插件后要等待一定的时间，等待相关 pod 就绪后再检查集群状态是否正常。\n健康检查 检查网络 # 在以下命令输出中检查 CoreDNS Pod 是否 Running 来确认其是否正常运行。 kubectl get pods --all-namespaces apiserver健康端点 curl -k https://localhost:6443/livez?verbose # 以上命令输出结果如下时证明 kube-apiserver 状态正常 [+]ping ok [+]log ok [+]etcd ok [+]poststarthook/start-kube-apiserver-admission-initializer ok [+]poststarthook/generic-apiserver-start-informers ok [+]poststarthook/start-apiextensions-informers ok [+]poststarthook/start-apiextensions-controllers ok [+]poststarthook/crd-informer-synced ok [+]poststarthook/bootstrap-controller ok [+]poststarthook/rbac/bootstrap-roles ok [+]poststarthook/scheduling/bootstrap-system-priority-classes ok [+]poststarthook/start-cluster-authentication-info-controller ok [+]poststarthook/start-kube-aggregator-informers ok [+]poststarthook/apiservice-registration-controller ok [+]poststarthook/apiservice-status-available-controller ok [+]poststarthook/kube-apiserver-autoregistration ok [+]autoregister-completion ok [+]poststarthook/apiservice-openapi-controller ok healthz check passed 同样的，可以使用 k8s 部署一个例如 nginx 的应用 pod ，然后使用 service 将资源公开，使用 curl 进行访问，测试集群是否正常，此处不做赘述。 参考资料 容器运行时CRI containerd 安装 containerd 配置 kubeadm 配置 kubeadm init 集群 helm 安装 cilium without kube-proxy 安装 ","permalink":"https://yanhuan0802.github.io/en/posts/install-kubernetes-on-ubuntu-with-kubeadm/","summary":"本文介绍基于 kubeadm + 内地网络 进行 k8s 集群部署。 本文介绍搭建单 master 节点 k8s 集群，适用于开发及测试，一般不适用生产环境。 环境准备 主机配置要求 k8s 集群要求机器","title":"基于 ubuntu 20.04 搭建 k8s 1.26.4 集群"}]