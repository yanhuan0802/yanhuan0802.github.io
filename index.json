[{"content":"环境准备 准备一台 linux 物理机 安装对应的 packer 软件 安装对应的 qemu kvm 软件 镜像构建 分别将以下 hcl 文件以及 user-data 文件放置在提前准备好的目录当中\nPacker Hcl 文件 packer { required_version = \u0026#34;\u0026gt;= 1.7.0, \u0026lt; 2.0.0\u0026#34; required_plugins { qemu = { source = \u0026#34;github.com/hashicorp/qemu\u0026#34; version = \u0026#34;\u0026gt;= 1.0.0, \u0026lt; 2.0.0\u0026#34; } } } variable \u0026#34;vm_name\u0026#34; { type = string default = \u0026#34;ubuntu-2004.qcow2\u0026#34; } source \u0026#34;qemu\u0026#34; \u0026#34;test\u0026#34; { iso_url = \u0026#34;https://releases.ubuntu.com/20.04/ubuntu-20.04.5-live-server-amd64.iso\u0026#34; iso_checksum = \u0026#34;5035be37a7e9abbdc09f0d257f3e33416c1a0fb322ba860d42d74aa75c3468d4\u0026#34; vm_name = var.vm_name output_directory = \u0026#34;output\u0026#34; http_directory = \u0026#34;http\u0026#34; boot_wait = \u0026#34;2s\u0026#34; boot_command = [ \u0026#34;\u0026lt;esc\u0026gt;\u0026lt;esc\u0026gt;\u0026lt;esc\u0026gt;\u0026#34;, \u0026#34;\u0026lt;enter\u0026gt;\u0026lt;wait\u0026gt;\u0026#34;, \u0026#34;/casper/vmlinuz \u0026#34;, \u0026#34;initrd=/casper/initrd \u0026#34;, \u0026#34;autoinstall ds=nocloud-net;s=http://{{.HTTPIP}}:{{.HTTPPort}}/\u0026#34;, \u0026#34;\u0026lt;enter\u0026gt;\u0026#34; ] shutdown_command = \u0026#34;echo \u0026#39;packer\u0026#39; | sudo -S shutdown -P now\u0026#34; headless = true format = \u0026#34;qcow2\u0026#34; accelerator = \u0026#34;kvm\u0026#34; qemu_binary = \u0026#34;/usr/libexec/qemu-kvm\u0026#34; qemu_img_args { convert = [ \u0026#34;-m\u0026#34;, \u0026#34;8\u0026#34; ] } ssh_username = \u0026#34;root\u0026#34; ssh_password = \u0026#34;Root123!\u0026#34; ssh_timeout = \u0026#34;30m\u0026#34; vnc_bind_address = \u0026#34;0.0.0.0\u0026#34; cpus = 8 memory = 8192 net_device = \u0026#34;virtio-net\u0026#34; disk_size = \u0026#34;100G\u0026#34; disk_compression = true } build { name = \u0026#34;ubuntu20-04\u0026#34; sources = [ \u0026#34;source.qemu.test\u0026#34; ] provisioner \u0026#34;shell\u0026#34; { pause_before = \u0026#34;20s\u0026#34; inline = [\u0026#34;echo \u0026#39;build success\u0026#39;\u0026#34;] } } Ubuntu auto install user-data 文件 #cloud-config autoinstall: version: 1 early-commands: - hostnamectl set-hostname ubuntu # update hostname even for the installer environment - dhclient # re-register the updated hostname identity: # hostname of the system hostname: ubuntu # root doesn\u0026#39;t work username: ubuntu # ubuntu password: \u0026#34;$6$FhcddHFVZ7ABA4Gi$MhQrLRAMZI65UOGGwxyCYRgolj13tIHC3/MRfyQQlP4nD9jgIdn63Ol2qlO3I8I/Gfdcsg7k58dTYOzz3LeqJ.\u0026#34; ssh: install-server: true allow-pw: true user-data: timezone: Asia/Shanghai disable_root: false ssh_pwauth: true users: - name: root lock_passwd: false plain_text_passwd: Root123! - name: ubuntu lock_passwd: false plain_text_passwd: Root123! sudo: ALL=(ALL) NOPASSWD:ALL network: version: 2 ethernets: zz-all-en: match: name: \u0026#34;en*\u0026#34; dhcp4: true dhcp-identifier: mac zz-all-eth: match: name: \u0026#34;eth*\u0026#34; dhcp4: true dhcp-identifier: mac keyboard: layout: en variant: us locale: en_US storage: swap: size: 0 layout: name: direct packages: - bc - cloud-init - git - curl - wget - openssl - vim late-commands: - sed -i -e \u0026#39;s/^#\\?PasswordAuthentication.*/PasswordAuthentication yes/g\u0026#39; /target/etc/ssh/sshd_config - sed -i -e \u0026#39;s/^#\\?PermitRootLogin.*/PermitRootLogin yes/g\u0026#39; /target/etc/ssh/sshd_config - sed -i \u0026#39;s/^#*\\(send dhcp-client-identifier\\).*$/\\1 = hardware;/\u0026#39; /etc/dhcp/dhclient.conf - echo \u0026#39;ubuntu ALL=(ALL) NOPASSWD:ALL\u0026#39; \u0026gt; /target/etc/sudoers.d/ubuntu - curtin in-target --target=/target -- chmod 440 /etc/sudoers.d/ubuntu 执行 Packer 打包命令 packer build qemu.pkr.hcl 参考文档 Install Packer Ubuntu Automatic installation ","permalink":"https://yanhuan0802.github.io/posts/packer-qemu-ubuntu2004/","summary":"环境准备 准备一台 linux 物理机 安装对应的 packer 软件 安装对应的 qemu kvm 软件 镜像构建 分别将以下 hcl 文件以及 user-data 文件放置在提前准备好的目录当中\nPacker Hcl 文件 packer { required_version = \u0026#34;\u0026gt;= 1.7.0, \u0026lt; 2.0.0\u0026#34; required_plugins { qemu = { source = \u0026#34;github.com/hashicorp/qemu\u0026#34; version = \u0026#34;\u0026gt;= 1.0.0, \u0026lt; 2.0.0\u0026#34; } } } variable \u0026#34;vm_name\u0026#34; { type = string default = \u0026#34;ubuntu-2004.qcow2\u0026#34; } source \u0026#34;qemu\u0026#34; \u0026#34;test\u0026#34; { iso_url = \u0026#34;https://releases.ubuntu.com/20.04/ubuntu-20.04.5-live-server-amd64.iso\u0026#34; iso_checksum = \u0026#34;5035be37a7e9abbdc09f0d257f3e33416c1a0fb322ba860d42d74aa75c3468d4\u0026#34; vm_name = var.vm_name output_directory = \u0026#34;output\u0026#34; http_directory = \u0026#34;http\u0026#34; boot_wait = \u0026#34;2s\u0026#34; boot_command = [ \u0026#34;\u0026lt;esc\u0026gt;\u0026lt;esc\u0026gt;\u0026lt;esc\u0026gt;\u0026#34;, \u0026#34;\u0026lt;enter\u0026gt;\u0026lt;wait\u0026gt;\u0026#34;, \u0026#34;/casper/vmlinuz \u0026#34;, \u0026#34;initrd=/casper/initrd \u0026#34;, \u0026#34;autoinstall ds=nocloud-net;s=http://{{.","title":"使用 Packer QEMU 插件构建自定义 Ubuntu 20.04 操作系统镜像"},{"content":" 本文介绍基于 kubeadm + 内地网络 进行 k8s 集群部署。 本文介绍搭建单 master 节点 k8s 集群，适用于开发及测试，一般不适用生产环境。 环境准备 主机配置要求 k8s 集群要求机器最低配置为 2CPU 2GRAM 关闭防火墙、交换分区、selinux # 防火墙 systemctl status firewalld # 如果没有firewalld.service，执行如下命令 sudo ufw status sudo ufw disable # 关闭swap swapoff -a cat /etc/fstab | grep swap # 删除或注释掉带有swap关键字的行 vi /etc/fstab # selinux # 检查 结果为Disabled即为关闭状态 apt update -y apt install -y selinux-utils getenforce # 如果selinux是启用状态，则需要永久关闭，关闭后重启机器方可生效 sed -i \u0026#39;s/SELINUX=enforcing/SELINUX=disabled/\u0026#39; /etc/selinux/config reboot 应用安装 安装容器运行时（CR） 自 1.24 版起，Dockershim 已从 Kubernetes 项目中移除，本文只介绍 containerd 的安装。 允许 iptables 检查桥接流量 # 确保overlay br_netfilter内核模块加载 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter # 为了Linux 节点上的 iptables 能够正确地查看桥接流量，需要确保在sysctl 配置中将 net.bridge.bridge-nf-call-iptables 设置为 1 # 设置所需的 sysctl 参数，参数在重新启动后保持不变 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF # 应用 sysctl 参数而不重新启动 sudo sysctl --system containerd安装 安装 apt repository # 删除旧版本（如果存在的话） sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update -y sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release software-properties-common sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null 安装 containerd sudo apt-get update -y sudo apt-get install containerd.io=1.6.20-1 配置 containerd sudo mkdir -p /etc/containerd containerd config default | sudo tee /etc/containerd/config.toml # 设置SystemdCgroup sudo sed -i \u0026#39;s/SystemdCgroup = false/SystemdCgroup = true/g\u0026#39; /etc/containerd/config.toml # 修改pause镜像地址 sudo sed -i \u0026#39;s/registry.k8s.io/registry.aliyuncs.com\\/google_containers/g\u0026#39; /etc/containerd/config.toml sudo systemctl restart containerd 配置镜像加速 mkdir -p /etc/containerd/certs.d/docker.io sed -i \u0026#39;s/\\(config_path *= *\\)\u0026#34;[^\u0026#34;]*\u0026#34;/\\1\u0026#34;\\/etc\\/containerd\\/certs.d\u0026#34;/\u0026#39; /etc/containerd/config.toml cat \u0026gt; /etc/containerd/certs.d/docker.io/hosts.toml \u0026lt;\u0026lt; EOF server = \u0026#34;https://docker.io\u0026#34; [host.\u0026#34;https://9ptmljtk.mirror.aliyuncs.com\u0026#34;] capabilities = [\u0026#34;pull\u0026#34;, \u0026#34;resolve\u0026#34;] EOF sudo systemctl restart containerd 安装 crictl VERSION=\u0026#34;v1.25.0\u0026#34; wget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz sudo tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin rm -f crictl-$VERSION-linux-amd64.tar.gz 设置运行时，crictl 默认连接到 unix:///var/run/dockershim.sock，我们需要将其改为 containerd 的 socket # 配置 sudo crictl config runtime-endpoint unix:///run/containerd/containerd.sock sudo crictl config image-endpoint unix:///run/containerd/containerd.sock # 检查结果 cat /etc/crictl.yaml 注意：如果第一步安装 crictl 失败，那么也可以在 kubelet 安装完成后执行容器运行时的配置，然后重启 kubelet ，因为在安装 kubelet 时也会自动安装 cri-tools ，我将这一步写到此处是为了区分不同的 runtime 安装kubeadm、kubelet 和 kubectl 在使用的机器上面都需要安装以下软件包 kubeadm：用来初始化集群的指令。 kubelet：在集群中的每个节点上用来启动 Pod 和容器等。 kubectl：用来与集群通信的命令行工具。 更新包索引、安装必要软件 sudo apt-get update -y sudo apt-get install -y apt-transport-https ca-certificates curl 从阿里镜像仓库下载密钥（无网络限制的话可以从 google 地址下载） sudo curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - 添加 k8s apt 仓库（无网络限制的话可以添加为 google 地址） sudo tee /etc/apt/sources.list.d/kubernetes.list \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; deb https://mirrors.aliyun.com/kubernetes/apt kubernetes-xenial main EOF 更新包索引，安装 kubelet、kubeadm 和 kubectl，并锁定其版本 # 旧版本清理 sudo apt remove -y kubeadm kubelet kubectl sudo apt autoremove -y # 安装 sudo apt-get update -y sudo apt-get install -y kubelet=1.26.4-00 kubeadm=1.26.4-00 kubectl=1.26.4-00 sudo apt-mark hold kubelet kubeadm kubectl 设置 crictl 运行时，crictl 默认连接到 unix:///var/run/dockershim.sock，我们需要将其改为 containerd 的 socket # 配置 sudo crictl config runtime-endpoint unix:///run/containerd/containerd.sock sudo crictl config image-endpoint unix:///run/containerd/containerd.sock # 检查结果 cat /etc/crictl.yaml 集群初始化 kubeadm init kubeadm config: 初始化配置文件，指定 apiServer endpoint 等地址 cat \u0026gt; /etc/kubernetes/config.yaml \u0026lt;\u0026lt; EOF apiVersion: kubeadm.k8s.io/v1beta3 kind: InitConfiguration nodeRegistration: criSocket: \u0026#34;unix:///run/containerd/containerd.sock\u0026#34; taints: [ ] imagePullPolicy: \u0026#34;IfNotPresent\u0026#34; localAPIEndpoint: # 公布 apiServer 正在监听的 IP 地址，需要替换为自己主机的 ip 地址 advertiseAddress: \u0026#34;10.10.98.36\u0026#34; bindPort: 6443 skipPhases: # 如果安装的网络插件为cilium, 可跳过 kube-proxy 的安装, 因为 cilium 内置 Host-Reachable Services 功能可以替换 kube-proxy - addon/kube-proxy --- apiVersion: kubeadm.k8s.io/v1beta3 kind: ClusterConfiguration kubernetesVersion: 1.26.4 # 公布 apiServer 正在监听的 IP 地址，需要替换为自己主机的 ip 地址 controlPlaneEndpoint: \u0026#34;10.10.98.36:6443\u0026#34; certificatesDir: \u0026#34;/etc/kubernetes/pki\u0026#34; imageRepository: \u0026#34;registry.aliyuncs.com/google_containers\u0026#34; EOF kubeadm init kubeadm init --config /etc/kubernetes/config.yaml 如果此步骤出错可运行kubeadm reset --force重置kubeadm状态，然后进行检查。 使非 root 用户可以运行 kubectl mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config root用户 export KUBECONFIG=/etc/kubernetes/admin.conf 默认情况下，出于安全原因，你的集群不会在控制平面节点上调度 Pod。 如果你希望能够在控制平面节点上调度 Pod， 例如用于开发的单机 Kubernetes 集群，请运行： kubectl taint nodes --all node-role.kubernetes.io/control-plane- 安装 helm 安装 k8s 包管理工具 helm，后续可以使用 helm 来进行应用安装。 curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg \u0026gt; /dev/null sudo apt-get install apt-transport-https --yes echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main\u0026#34; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list sudo apt-get update sudo apt-get install helm 安装网络插件 你必须部署一个基于 Pod 网络插件的容器网络接口 (CNI)，以便你的 Pod 可以相互通信。 在安装网络之前，集群 DNS (CoreDNS) 将不会启动。 每个集群只能安装一中 Pod 网络插件。 常见的pod网络插件有 Calico、Flannel、Cilium 等，本文以 Cilium 插件安装做示例，其余两种插件安装可参考对应的官网。 Cilium # add helm repo helm repo add cilium https://helm.cilium.io/ # helm install API_SERVER_IP=10.10.98.36 API_SERVER_PORT=6443 helm upgrade --install cilium cilium/cilium \\ --namespace kube-system \\ --version 1.13.1 \\ --set kubeProxyReplacement=strict \\ --set k8sServiceHost=${API_SERVER_IP} \\ --set k8sServicePort=${API_SERVER_PORT} \\ --set operator.replicas=1 ### 参数说明 kubeProxyReplacement: cilium agent是否在底层 Linux 内核支持缺失的情况下退出, 没有安装 kube-proxy 的情况下配置 strict, 表示内核不支持的话就退出. k8sServiceHost: apiserver ip k8sServicePort: apiserver port 由于每个人使用的机器网络状况不一样，所以安装网络插件后要等待一定的时间，等待相关 pod 就绪后再检查集群状态是否正常。 健康检查 检查网络 # 在以下命令输出中检查 CoreDNS Pod 是否 Running 来确认其是否正常运行。 kubectl get pods --all-namespaces apiserver健康端点 curl -k https://localhost:6443/livez?verbose # 以上命令输出结果如下时证明 kube-apiserver 状态正常 [+]ping ok [+]log ok [+]etcd ok [+]poststarthook/start-kube-apiserver-admission-initializer ok [+]poststarthook/generic-apiserver-start-informers ok [+]poststarthook/start-apiextensions-informers ok [+]poststarthook/start-apiextensions-controllers ok [+]poststarthook/crd-informer-synced ok [+]poststarthook/bootstrap-controller ok [+]poststarthook/rbac/bootstrap-roles ok [+]poststarthook/scheduling/bootstrap-system-priority-classes ok [+]poststarthook/start-cluster-authentication-info-controller ok [+]poststarthook/start-kube-aggregator-informers ok [+]poststarthook/apiservice-registration-controller ok [+]poststarthook/apiservice-status-available-controller ok [+]poststarthook/kube-apiserver-autoregistration ok [+]autoregister-completion ok [+]poststarthook/apiservice-openapi-controller ok healthz check passed 同样的，可以使用 k8s 部署一个例如 nginx 的应用 pod ，然后使用 service 将资源公开，使用 curl 进行访问，测试集群是否正常，此处不做赘述。 参考文档 容器运行时CRI containerd 安装 containerd 配置 kubeadm 配置 kubeadm init 集群 helm 安装 cilium without kube-proxy 安装 ","permalink":"https://yanhuan0802.github.io/posts/install-kubernetes-on-ubuntu-with-kubeadm/","summary":"本文介绍基于 kubeadm + 内地网络 进行 k8s 集群部署。 本文介绍搭建单 master 节点 k8s 集群，适用于开发及测试，一般不适用生产环境。 环境准备 主机配置要求 k8s 集群要求机器最低配置为 2CPU 2GRAM 关闭防火墙、交换分区、selinux # 防火墙 systemctl status firewalld # 如果没有firewalld.service，执行如下命令 sudo ufw status sudo ufw disable # 关闭swap swapoff -a cat /etc/fstab | grep swap # 删除或注释掉带有swap关键字的行 vi /etc/fstab # selinux # 检查 结果为Disabled即为关闭状态 apt update -y apt install -y selinux-utils getenforce # 如果selinux是启用状态，则需要永久关闭，关闭后重启机器方可生效 sed -i \u0026#39;s/SELINUX=enforcing/SELINUX=disabled/\u0026#39; /etc/selinux/config reboot 应用安装 安装容器运行时（CR） 自 1.24 版起，Dockershim 已从 Kubernetes 项目中移除，本文只介绍 containerd 的安装。 允许 iptables 检查桥接流量 # 确保overlay br_netfilter内核模块加载 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.","title":"基于 ubuntu 20.04 搭建 k8s 1.26.4 集群"}]